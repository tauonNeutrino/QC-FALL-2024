{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oO3hLLHfHMp2",
    "outputId": "61b7f575-11ae-4993-9a9f-6f85120924e0"
   },
   "outputs": [],
   "source": [
    "!pip install \\\n",
    "  dwave-ocean-sdk \\\n",
    "  dwave-system \\\n",
    "  dwave-neal \\\n",
    "  #dwave-inspector \\\n",
    "  #mplcyberpunk\n",
    "#!dwave install inspector -y\n",
    "import json\n",
    "import dimod\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from dwave.system import LeapHybridSampler, DWaveSampler, EmbeddingComposite\n",
    "# import dwavebinarycsp\n",
    "import dwave.inspector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.cluster import rand_score, adjusted_rand_score\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "#import mplcyberpunk\n",
    "from matplotlib import colors\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sc96QBJaHMp3"
   },
   "outputs": [],
   "source": [
    "def get_max_coeff(mydict):\n",
    "\treturn max([abs(v) for v in mydict.values()])\n",
    "\n",
    "def angle_diff(a, b):\n",
    "\treturn 2*abs((a - b + 0.5) % 1.0 - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvDvH2BPHMp4"
   },
   "outputs": [],
   "source": [
    "\n",
    "def g_from_AJpaper_QUBO(m, Dij):\n",
    "\treturn 1 + math.log(Dij*m)\n",
    "\n",
    "def create_qubo(df, m, nv):\n",
    "\tZ = df['z']\n",
    "\tT = df['theta']\n",
    "\tP = df['momentum']\n",
    "\tnT = len(Z)\n",
    "\n",
    "\tqubo = defaultdict(float)\n",
    "\tDij_max = 0\n",
    "\n",
    "\tfor k in range(nv):\n",
    "\t\tfor i in range(nT):\n",
    "\t\t\tfor j in range(i+1, nT):\n",
    "\t\t\t\tDij = ((Z[i] - Z[j])**2 + angle_diff(T[i], T[j])**2) ** 0.5\n",
    "\t\t\t\tDij_max = max(Dij_max, Dij)\n",
    "\t\t\t\tqubo[(i+nT*k, j+nT*k)] = g_from_AJpaper_QUBO(m, Dij) + min(P[i], P[j])\n",
    "\n",
    "\tlam = 1.0 * get_max_coeff(qubo)\n",
    "\n",
    "\tfor i in range(nT):\n",
    "\t\tfor k in range(nv):\n",
    "\t\t\tqubo[(i+nT*k, i+nT*k)] -= lam\n",
    "\t\t\tfor l in range(k+1, nv):\n",
    "\t\t\t\tqubo[(i+nT*k, i+nT*l)] += 2 * lam\n",
    "\n",
    "\treturn qubo\n",
    "\n",
    "def run_qa(df, nv):\n",
    "\tnv = nv\n",
    "\tqubo = create_qubo(df, nv-1, nv)\n",
    "\tstrength = math.ceil(get_max_coeff(qubo))\n",
    "\tsampler = EmbeddingComposite(DWaveSampler(token='DEV-(redacted)'))\n",
    "\tresponse = sampler.sample_qubo(qubo, num_reads=100, chain_strength=strength, annealing_time = 50) # Don't mess with this until you understand it\n",
    "\tbest = response.first.sample\n",
    "\tset_solution_from_annealer_response(df, best)\n",
    "\n",
    "def set_solution_from_annealer_response(df, response):\n",
    "\tnT = len(df)\n",
    "\ttrack_to_vertex = [None] * nT\n",
    "\n",
    "\tif len(response.items()) == 0:\n",
    "\t\tprint(\"Invalid solution! Annealer returned an error.\")\n",
    "\t\tdf['qagroup'] = None\n",
    "\t\treturn False\n",
    "\n",
    "\tfor num, bool in response.items():\n",
    "\t\tif bool == 1:\n",
    "\t\t\ti = num % nT # track number\n",
    "\t\t\tk = num // nT # vertex number\n",
    "\n",
    "\t\t\tif track_to_vertex[i] != None:\n",
    "\t\t\t\tprint(\"Invalid solution! Track assigned to multiple vertices.\")\n",
    "\t\t\t\tdf['qagroup'] = None\n",
    "\t\t\t\treturn False\n",
    "\t\t\telse:\n",
    "\t\t\t\ttrack_to_vertex[i] = k\n",
    "\n",
    "\tif None in track_to_vertex:\n",
    "\t\tprint(\"Invalid solution! Track assigned to no vertex.\")\n",
    "\t\ttrack_to_vertex = None\n",
    "\t\treturn False\n",
    "\n",
    "\telse:\n",
    "\t\tpass\n",
    "\tdf['qagroup'] = track_to_vertex\n",
    "\treturn True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-0miJooHMp5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_reasonable_sizes_for_plotting_momentum(P):\n",
    "\treturn [500 * p**0.6 for p in P]\n",
    "\n",
    "def rand_cmap_for_plotting(nlabels, type='bright'):\n",
    "\n",
    "\tif type == 'bright':\n",
    "\t\trandHSVcolors = [((np.random.uniform(low=0.0, high=1)),\n",
    "\t\t\t\t\t\t  np.random.uniform(low=0.7, high=1),\n",
    "\t\t\t\t\t\t  np.random.uniform(low=0.9, high=1)) for _ in range(nlabels)]\n",
    "\n",
    "\t\trandRGBcolors = []\n",
    "\t\tfor HSVcolor in randHSVcolors:\n",
    "\t\t\trandRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "\t\treturn randRGBcolors\n",
    "\tif type == 'soft':\n",
    "\t\tlow = 0.6\n",
    "\t\thigh = 0.95\n",
    "\t\trandRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "\t\t\t\t\t\t  np.random.uniform(low=low, high=high),\n",
    "\t\t\t\t\t\t  np.random.uniform(low=low, high=high)) for _ in range(nlabels)]\n",
    "\t\treturn randRGBcolors\n",
    "\n",
    "\n",
    "palette = rand_cmap_for_plotting(30, type='bright')\n",
    "\n",
    "\n",
    "def plot_clusters(df, grouping, title, saveto=None):\n",
    "\tall_zs = df['z']\n",
    "\tall_thetas = df['theta']\n",
    "\tall_ps = df['momentum']\n",
    "\n",
    "\tcolors = [palette[i] for i in grouping]\n",
    "\tscaled = get_reasonable_sizes_for_plotting_momentum(all_ps)\n",
    "\tplt.figure()\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel(\"Z (normalized)\")\n",
    "\tplt.ylabel(\"Î¸ (normalized)\")\n",
    "\tplt.grid()\n",
    "\tfor (i, z) in enumerate(all_zs):\n",
    "\t\tplt.scatter(z, all_thetas[i], color=colors[i], s=scaled[i], alpha=0.5)\n",
    "\t\t# mplcyberpunk.make_scatter_glow()\n",
    "\tif saveto is not None:\n",
    "\t\tplt.savefig(saveto)\n",
    "\t\tplt.close() # avoid displaying the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38wn_YrVHMp5"
   },
   "outputs": [],
   "source": [
    "def score_clusters(truth, solution):\n",
    "\tif len(solution) == 0:\n",
    "\t\treturn 0.0\n",
    "\tif solution.isnull().any():\n",
    "\t\treturn 0.0\n",
    "\treturn 100.0 * adjusted_rand_score(truth, solution)\n",
    "\n",
    "def get_rand_from_number_of_vertices(v):\n",
    "\telem = v[np.random.randint(len(v))]\n",
    "\tv.remove(elem)\n",
    "\treturn elem\n",
    "\n",
    "def generate_clusters(nt=16, nv=2, std=0.02):\n",
    "\n",
    "\tz_range = 1 # 0 to 1\n",
    "\ttheta_range = 1 # 0 to 1 (we're acting like we squished the ranges)\n",
    "\tnum_tracks = nt\n",
    "\n",
    "\tp = np.random.rand(num_tracks)\n",
    "\tp = 1/(p**2 + 0.001) # 3 orders of magnitude diff between min and max. corresponds to: 30 MeV, 30 GeV scaled\n",
    "\tp /= p.max()\n",
    "\n",
    "\tp = np.sort(p)[::-1].tolist()\n",
    "\n",
    "\thard_ps = p[:nv]\n",
    "\tsoft_ps = p[nv:]\n",
    "\n",
    "\tvertex_zs = np.random.rand(nv) * z_range\n",
    "\tvertex_thetas = np.random.rand(nv) * theta_range\n",
    "\n",
    "\tpoints_per_cluster = num_tracks // nv\n",
    "\tremainder = num_tracks % nv\n",
    "\n",
    "\tall_zs = []\n",
    "\tall_thetas = []\n",
    "\tall_ps = []\n",
    "\ttruth = [] # which cluster each point belongs to\n",
    "\tfor i in range(nv):\n",
    "\t\tz = vertex_zs[i]\n",
    "\t\ttheta = vertex_thetas[i]\n",
    "\n",
    "\t\t# -1 because we're going to add the vertex itself too\n",
    "\t\ttoadd = points_per_cluster - 1 + (1 if i < remainder else 0)\n",
    "\t\tfor j in range(toadd):\n",
    "\t\t\tall_zs.append(z + np.random.normal(scale=std))\n",
    "\t\t\tall_thetas.append((theta + np.random.normal(scale=std)) % 1.0) # modulo 1.0 to keep it in the range\n",
    "\t\t\tall_ps.append(get_rand_from_number_of_vertices(soft_ps))\n",
    "\t\t\ttruth.append(i)\n",
    "\t\tall_zs.append(z)\n",
    "\t\tall_thetas.append(theta)\n",
    "\t\tall_ps.append(get_rand_from_number_of_vertices(hard_ps))\n",
    "\t\ttruth.append(i)\n",
    "\t# all_zs = np.array(all_zs)\n",
    "\t# all_thetas = np.array(all_thetas)\n",
    "\tDF = pd.DataFrame({'z': all_zs, 'theta': all_thetas, 'momentum': all_ps, 'truegroup': truth})\n",
    "\tDF.to_csv('TEST_DATA_WEEK_6.csv')\n",
    "\treturn DF\n",
    "\n",
    "\t# return (n, all_zs, all_thetas, all_ps, truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "RCbXJx9iCjnS",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_test(nv, nt, chain_length, chain_strength, annealing_time, sweeps):\n",
    "    # Set standard deviation for cluster generation\n",
    "    std = 0.06\n",
    "\n",
    "    # Generate synthetic clusters\n",
    "    df = generate_clusters(nt=nt, nv=nv, std=std)\n",
    "\n",
    "    # Run Quantum Annealing\n",
    "    qubo = create_qubo(df, chain_length, nv)\n",
    "    sampler = EmbeddingComposite(DWaveSampler(token='DEV-0c064bac1884ffbe99c32c0c572a9390eb918320'))\n",
    "\n",
    "    # Perform sampling with provided parameters\n",
    "    response = sampler.sample_qubo(\n",
    "        qubo,\n",
    "        num_reads=sweeps,\n",
    "        chain_strength=chain_strength,\n",
    "        annealing_time=annealing_time\n",
    "    )\n",
    "\n",
    "    # Extract and validate solution\n",
    "    best_sample = response.first.sample\n",
    "    valid_solution = set_solution_from_annealer_response(df, best_sample)\n",
    "\n",
    "    if not valid_solution:\n",
    "        return None, None\n",
    "\n",
    "    # Check and score the solution\n",
    "    qascore = score_clusters(df['truegroup'], df['qagroup'])\n",
    "    print(\"Score:\", qascore)\n",
    "\n",
    "    # Save results to CSV for this test\n",
    "    df['qascore'] = qascore\n",
    "    df.to_csv(f\"results_nv_{nv}_nt_{nt}.csv\", index=False)\n",
    "\n",
    "    # Return DataFrame and score for comparison and plotting\n",
    "    return qascore, df\n",
    "\n",
    "def test_parameter_combinations(test_parameters):\n",
    "    best_overall_score = 0\n",
    "    best_overall_params = {}\n",
    "    best_df = None\n",
    "\n",
    "    # Set fixed values for nv and nt\n",
    "    nv = 4\n",
    "    nt = 10\n",
    "\n",
    "    for params in test_parameters:\n",
    "        print(\"Test parameters:\", params)\n",
    "        # Run test for current parameter set\n",
    "        qascore, df = run_test(\n",
    "            nv=nv,\n",
    "            nt=nt,\n",
    "            chain_length=params[\"chain_length\"],\n",
    "            chain_strength=params[\"chain_strength\"],\n",
    "            annealing_time=params[\"annealing_time\"],\n",
    "            sweeps=params[\"sweeps\"]\n",
    "        )\n",
    "\n",
    "        # Track best configuration and score\n",
    "        if qascore is not None and qascore > best_overall_score:\n",
    "            best_overall_score = qascore\n",
    "            best_overall_params = {**params, \"qascore\": qascore}\n",
    "            best_df = df\n",
    "\n",
    "    # Plot the clusters of the best configuration if found\n",
    "    if best_df is not None:\n",
    "        title = f\"Best Annealer Solution with ARI={best_overall_score:.1f}%\"\n",
    "        plot_clusters(best_df, best_df['qagroup'], title)\n",
    "\n",
    "    # Print and return best configuration\n",
    "    print(f\"Best configuration with highest Adjusted Rand Index:\\n{best_overall_params}\")\n",
    "    return best_overall_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "dQ3j7M57Ft8r",
    "outputId": "84c2d20b-9fc6-4704-9091-1eaf623622d4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# New function to graph the results of the parameter tests\n",
    "def graph_results(parameter_test_results):\n",
    "    chain_lengths = [result[\"chain_length\"] for result in parameter_test_results]\n",
    "    scores = [result[\"qascore\"] for result in parameter_test_results]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(chain_lengths, scores, marker='o', color='b', label=\"ARI Score\")\n",
    "    plt.xlabel(\"Chain Length\")\n",
    "    plt.ylabel(\"Adjusted Rand Index (ARI) Score (%)\")\n",
    "    plt.title(\"ARI Scores for Different Chain Lengths\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Modified run_dynamic_chain_length_test function to store results for graphing\n",
    "def run_dynamic_chain_length_test_with_graph(nv, nt, chain_strength, annealing_time, sweeps, chain_length_range):\n",
    "    best_overall_score = 0\n",
    "    best_overall_params = {}\n",
    "    parameter_test_results = []\n",
    "\n",
    "    for chain_length in chain_length_range:\n",
    "        print(f\"Testing chain length: {chain_length:.1f}\")\n",
    "        trials = 30\n",
    "        avg_score = 0\n",
    "        for i in range(trials):\n",
    "            qascore, df = run_test(\n",
    "                nv=nv,\n",
    "                nt=nt,\n",
    "                chain_length=chain_length,\n",
    "                chain_strength=chain_strength,\n",
    "                annealing_time=annealing_time,\n",
    "                sweeps=sweeps\n",
    "            )\n",
    "            if qascore is None:\n",
    "                qascore = 0\n",
    "            avg_score += qascore\n",
    "\n",
    "        avg_score /= trials\n",
    "        parameter_test_results.append({\n",
    "            \"chain_length\": chain_length,\n",
    "            \"qascore\": avg_score\n",
    "        })\n",
    "\n",
    "        print(f\"Average score for chain length {chain_length:.1f}: {avg_score}\")\n",
    "\n",
    "        if avg_score > best_overall_score:\n",
    "            best_overall_score = avg_score\n",
    "            best_overall_params = {\n",
    "                \"chain_length\": chain_length,\n",
    "                \"chain_strength\": chain_strength,\n",
    "                \"annealing_time\": annealing_time,\n",
    "                \"sweeps\": sweeps,\n",
    "                \"qascore\": avg_score\n",
    "            }\n",
    "\n",
    "    # Graph the results after all tests are complete\n",
    "    graph_results(parameter_test_results)\n",
    "\n",
    "    print(f\"Best configuration with highest ARI for chain lengths {chain_length_range}:\\n{best_overall_params}\")\n",
    "    return best_overall_params\n",
    "\n",
    "# Run the modified test with nv, nt, and a dynamic chain length range\n",
    "nv = 4  # Number of vertices\n",
    "nt = 10  # Number of tracks\n",
    "chain_length_range = np.arange(1.5, 3.1, 0.1)  # Chain lengths from 1.5 to 3 in 0.1 increments\n",
    "base_parameters = {\n",
    "    \"chain_strength\": 1.5,\n",
    "    \"annealing_time\": 80,\n",
    "    \"sweeps\": 50\n",
    "}\n",
    "\n",
    "# Execute the function with additional plotting\n",
    "best_params_found = run_dynamic_chain_length_test_with_graph(\n",
    "    nv=nv,\n",
    "    nt=nt,\n",
    "    chain_strength=base_parameters[\"chain_strength\"],\n",
    "    annealing_time=base_parameters[\"annealing_time\"],\n",
    "    sweeps=base_parameters[\"sweeps\"],\n",
    "    chain_length_range=chain_length_range\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSomk0dnGste"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
